
l@esocp.py
from pydantic import BaseModel, constr
fron fastapi import WebSocket
from typing import List
fron openshift.dynamic import DynamicClient
from openshift.helper.userpassauth import OCPLoginConfiguration I
ron kubernetes import client
from kubernetes.client.exceptions import Apitxception
from kubernetes.stream import strean
from ..utils.general import timeout
import time, asyncio
class Cluster(DynamicClient):
name: conste(nax_length=256) = None
region: constr(max_length=256) = None
token_expires: int = @
def check_token(sel#):
if time.time() > self.token_expires:
return False
return True
def get_namespace_pods(self, namespace: str}:
return self.resources.get(api_version="v1‘, kind="Pod*).get(namespacesnamespace)

def get_namespace_pods(self, nawespace: str):
return self.resources.get(api_version="vi", kind="Pod’).get(namespace=namespace)
class Clustertanager(BaseModel):
clusters: List[Cluster] = {]
class Config:
arbitrary types_allowed = True
def get_cluster_conneciton(self, cluster_name: str, username: str = None) -> Cluster:
for cluster in self.clusters:
if cluster.name == cluster_name:
if username:
if cluster.configuration.ocp_username != username:
continue
if cluster. check_token():
return cluster
else:
self.clusters.renove(cluster)
else:
return None
def connect_cluster(self, api_url: str, cluster_nase: str = None, username: str = None, password: str - None, tokensNone, region="") -> Cluster:
if not username and not password:
if token:
config = OCPLoginConfiguration(api_uri, api_key-{"authorization”; “Bearer “ + token})
else:
raise Exception(“Username and password or token is required”)
else: I
config = OCPLoginConfiguration(api_url, ocp_username-username, ocp_password=password)
config.verify_ssl = False
if not token:
config.get_token()
api_cli = client .apiClient (configuration=config)
cluster = Cluster(api_cli)
cluster.token_expires = cluster.configuration.token["expires_in”] + tine.time()
cluster.name = cluster_name
cluster.region = region
self. clusters. append(cluster)
return cluster
class Pod(BaseModel):
name: conste(max_length-256) = None
cluster: Cluster = None
namespace: constr(max_length=256) = None
state: constr(max_length-256) = None

namespace: constr(max_length=256) = None
state: constr(max_length=-256) = None
class Config:
arbitrary types allowed = True
@timeout(6a, “Pod timed out deletion")
def wait_for_pod_deletion(self):
pod = self-cluster.resources. get(api_version="v1', kind="Pod" }.get(namespace=self.nanespace, name=self.nawe)
while pod.status.phase != “Pending”:
try:
pod « self.cluster.resources.get(api_version=‘vi', kind='Pod').get(nanespace=self.namespace, nane=self.name)
except ApiException:
pass
time.sleep(@.s)
return True
Gtimeout(63, "Pod timed out initializing")
def wait_for_pod_running(self):
pod = self.cluster.resources.get(api_version-"vi', kind="Pod").get(namespace-self. namespace, nane-self.name)
while pod.status.phase != “Running”:
try:
pod = sel¥.cluster.resources.get(api_version=‘vi", kind-"Pod").get(nanespace=self .namespace, name-self.name)
except ApiException:
pass
time.sleep(@.5)
return True
def exec_pod(self, command: list): I
api = client. CoreViApi (self.cluster. client)
return strean(api.connect_get_namespaced_pod_exec, self.name, self.namespace, conmand-conmand, stdin-False, stdout-True, stderr-True, tty-False)
def delete_pod(self):
pod = self. cluster.resources.get(api_version=‘vi', kind='Pod")
pod.delete(namespacecself.nanespace, name=sel¥.nane)
self.wait_for_pad_deletion()
self.wait_for_pod_running()
return True
def delete_pod_force(self):
pod = self.cluster.resources.get(api_version="vi', kind="Pod")
pod.delete(namespace=self.namespace, same-self.name, grace_period_seconds=0)
return True
def delete_pod_no_wait(self}:
pod = self.cluster.resources.get(api_version="vi', kind=‘Pod*}
ee be anak

def delete_pod_no_wait(self):
pod = self.cluster.resources.get(api_version="vi", kind="Pod")
pod.delete(namespace-self.namespace, name-seif.nane)
return True
async def stream_logs(self, websocket: WebSocket):
api = client. Corevivpi(self.cluster.client)
log_stream = stream(api.connect_get_namespaced_pod_exec, self.nane, self-nanespace, comnmand=["/bin/bash”,"-c","STAIL_LOGS™],
stdout=True, stderr=True, stdin-False, tty-False, _preload_content-False)
try:
while log_stream.is_open()+
Jog_stream.update(timeout=1)
if log_stream.peek_stdout():
await websocket.send_text(log_strean.read_stdout())
if log_stream.peek_stderr():
await websocket.send_text(log_stream.read_stderr())
await asyncio.sleep(@.1)
except Exception as e+
return
finally:
await websocket.close()
'@ngServiceNOw.py
# Code From Athena, Modified
from pydantic import BaseModel
from requests import get, post
from ..config import SERVICE_NOW_GROUP_ID, SERVICE_NOW USERNAME, SERVICE_NOW_PASSWORD, SERVICE_NOW_URL, SERVICE_NOW_ASSUME_USERNAME
class Incident (BaseModel): I
title: str
description: str
technology: str
dest_group: str
tequila: bool = False
class Servicenou():
def __ init__(self, username, password, api_url):
self.usernane = username
self.password = password
self.api_url = api_url
self.headers = {"Content-Type": “application/json”, "Accept": "application/Json"}
def get_call(self, call_number):
req = get(self.api_url, headers=self.headers, paramse{ ‘number’: cali_nunber},
auth=(self.username, self. password), verify-False)
return req.json()

ee 7 _
auth(self.username, self.password), verify-False)
return req.jsen()
class Servicetiow(ServiceNow):
def init__(self, usernane, password, api_url):
super()-__init__(username, password, api_url)
# Adds attributes to the incident body (what we will see in the incident
self.incident_body = {
“category”: “ae",
“subcategory”: "ams",
“state; “oTm",
“contact_type": “Self-service”,
“location”: “7188.n7g8n.n12~22",
“u_department™: "74887277",
"impact": 2,
"urgency": 2,
“u_perational_ispact”: “Hurricane”,
“network”: “orn 027
+
def get_user_id(self, username):
req = get(F”{SERVICE_NOW_URL}/now/table/sys_user?user_name=(usernane}&sysparm fields=sys_id&sysparm_limit-3",
auth=(self.username, self.password), verifysFalse)
return req. json()[ “result” ][O]["sys_id™}
def get_user_info(self, user_id):
response = get(FW{SERVICE_NOW_URL}/now/table/sys_user/{user_id}”,
auth-(self.username, self.password), verify-False)
return response. json() I
def get_service_details(self, technology):
response = get(#"{SERVICE_NOW_URL}/now/table/cadb_rel_ci?syspara_queryachild.naneL IKE(technology}%Separent .nameLAke&sysparm_fields-parent, child, parent.sys_id,child.sys_id&sysparm_display_value=true",
authe(self-username, self.password), verify-False)
return response. json()
def get_group_details(self, search):
response = get(f"{SERVICE_NOW_URL}/now/table/sys_user_group?sysparm_query=nameLIKE{ search}&sysparm_Fields=sys_id&sysparm_limit=3",
autha(self.username, self-password), verify-False)
if response. json():
return response. json()["result”][@}{"sys_id”]
response = get("{SERVICE_NOW_URL}/now/table/sys_user_group?sysparm_query=emailLIKe{search}&sysparm_fields-sys_id@sysparm_limit=3",
auth=(self.username, self.password), verify-False)
if response. json():
return response. json()[“result”][@]["sys_id”]
return SERVICE_NOW_GROUP_ID

EE NE
return response. json(){"result”](@]{"sys_id"]
return SERVICE_NOW_GROUP_ID
def post_call(self, title, description, technology, dest_group, tequila):
user_id = self.get_user_id(SERVICE_NOb_ASSUME_USERNAME)# Gets the user id of the user who opened the incident
user_info = self.get_user_info(user_id)# Gets the user info of the user who opened the incident
service_info = self.get_service detai1s(technology)
# Adds the description to the incident body
self.incident_body[“description"] = description
self.incident_body[“u_phone voip] = user_info[ ‘result” ][’u_phone_voip*]
self incident_body["u_wobile_phone"] = user_infof ‘result’ }{‘u_phone_voip’ ]
self-incident_body["u_computer_name”] = user_info["result']['u_phone_voip"]
self.incident_bady["opened_by”] = user_id
self.incident_body[“caller_id™] = user_id
self. incident _body{"service_offering”] = service_info[ "result" ][@]{"child"]["display_value"]
self.incident_body["business_service"] = service_infof “result” ][@][ "parent" ][“display_value”]
self.incident_body[“short_description"] = title
self. incident_body["u_impact_technology"] = "S9@f3178148a8e5e20d266d3b1ed658c"
self.incident_body[“assignment_group"] = self.get_group_details(dest_graup)
if tequila:
self.incident_body[“u_system failure”] = True
else:
self-incident_body[“u_system_failure"] = False
self incident_body{"u_open_for"] = “17w* 173"
# Posts the API request to open a new incident
response = post(self.api_url, headers-self-headers, json-self. incident_body,
auth=(self.username, sel¥.password), verifysFalse)
# Returns the incident number after it has been opened
return response. json()
I
def create_incident(incident : Incident):
snow = ServiceNow(SERVICE_NOW_USERNAME, SERVICE_NOW_PASSWORD, #7 {SERVICE_NOW_URL}now/table/incident?sysparm_display_value=true’)
return snow.post_call(titlesincident.title,description-incident.description, technology=incident.technology, dest_group=incident.dest_group, tequila-incident tequila)
def get_incident (incident_number):
show = SePviceNow(SERVICE_NOH_USERNAME, SERVICE NOH PASSWORD, f°{SERVICE_NOW_URL}now/table/incident?sysparm_display_value-true")
return snow. get_call (incident_number)
1@HShMQ. py
from .Host import Host
from ..config import VICTORIA_QUERY_METRICS_URL, REQUESTS_CLIENT, DEFAULT_MQ_ CHANNEL, MQ_AUTH
from fastapi import HTTPEXxception, status
rom pydantic import constr
import. pymqi,
class QMGR(Host):
qm: conste(max_length=256) = None
Listen_port: constr(max_length=256) = None
nee ey | nannen

class QHGR(Host):
gn: constr(max_length=256) = None
listen_port: constr(max_length=256) = None
version: constr(max_length-256) = None
pymgi_handier: pymqi.QueueManager = Hone
def __ init__(self, **kwargs):
Super().__init__(**kwargs)
self.get_connection_details()
class Config:
arbitrary_types_allowed = True
def get_connection_details(self):
Info = REQUESTS_CLIENT.get(VECTORIA QUERY METRICS_URL + f*wmq_qngr_info{{queue_manager="{self.qu}"}}').json{)
if not info[ ‘data’ ][ ‘result’ ]:
raise HTTPException(status-HTTP_4@4_NOT_FOUND, “Queue Manager Not Found")
self.Listen_port = info[ ‘data’ }[ result‘ ][@]{ ‘metric’ ][*port"]
self.hostnane = info[ ‘data’ ][ ‘result’ ][@J[‘metric’ ][‘host’]
if not self.ip:
self .dns_to_ip()
def get_qn_by_host(self):
info = REQUESTS_CLIENT.get(VICTORIA_QUERV_METRICS URL + #*wmq_qngr_info{{host="{self.hostname}"}}")-json()
self.qu = info[ ‘data’ ][‘result’ ][@]["netric’ }[ ‘queue_manager’]
def connect(sel):
if self.pymgi_handler: I
if self .pymgi_handler.is_connected:
return “Already Connected”
if not self.qm and sel¥.hostnane:
self.get_qn_by_host()
Af not self.ip or not self.hostname:
self .get_connection_details()
if not self.ip or not self.listen_port:
raise Exception("Not Enough Details For Qa”)
self.pynqi_handler = pymqi.connect(self.qm, DEFAULT_MQ CHANNEL, f*{self.ip}({self.1isten_port})"}
def disconnect(self):
sel¥.pymgi_handler.disconnect()
def reset_channel (self, channel_name):
cee nner ent IE eecnt handtaa

ee Ee ee
def reset_channel(sel¥, channel_name):
mq_pcf_exec = pynqi.PCFExecute(self .pymqi_handler)
channei_config = {
pymgi.CHOCFC.MOCACH_CHANNEL_NAME: channel_name,
y
nq_pcf_exec .MQCHD_RESET_CHANNEL (channel_config)
return True
def restore_from_diq(self):
sel¥._connect_and_execute_no_output(MQ_AUTH["username”], MQ_AUTH["password"},
f*pkill ~9 .*runmgdlg.*; echo “ACTION (RETRY) | timeout -s 9 6s /opt/nqn/bin/runngdlq SYSTEM.DEAD.LETTER.QUEUE {sel¥.qn}")
retupn True
1@#$Zookeeper.py
from .Host import Host
from pydantic import constr
class Zookeeper(Host):
Listen_port: constr(max_length=5) = "21817
def echo():
return True
1@#$__init__-py
1@9$_init__.py I
1@NSauth. py
feom fastapi.responses import RedirectResponse
from fastapi.routing import APIRouter
fron fastapi.security import APIkeyCookie
from fastapi import Depends, Response, Request
from ..config import ASYNC_REQUESTS_CLIENT, GRIFFIN AUTH_URL, AVATAR_URL
from datetime import timedelta
from tine import time
COOKIE_SCHEME = APIKeyCookie(name="access_token”}
async def get_logged_user(access_token: str = Depends(COOKIE_SCHEME)):
request = avait ASVYNC_REQUESTS_CLIENT.get(f*{GRIFFIN_AUTH_URL}/authorization/validate?tokene{access_token}”, verify ssl-False)
if request.status > 299:
return False
request = await ASVNC_REQUESTS_CLIENT.get(#*{GRIFFIN_AUTH_URL}/authorization/getClains?token={access_token}", verify ssl-False)
response = await request. json()
cee wy ENE ewan gad fen cnenenf 'eAthAerrunthinme! Te

ee EES
return False
request = await ASVNC_REQUESTS CLIENT. get(f*{GRIFFIN_AUTH_URL}/authorizstion/getClains ?token=(access_token}", verify_ss]-False)
response = await request. json()
response[“avatar"] = f"{AVATAR_URL}/{response[ "sAMAccountName* ]}”
return response
router = APIRouter(tags=["Auth"], prefix-"/auth")
@router.get(“/login")
async def login():
return RedirectResponse("/authentication?tokenConsumerURL=/auth/me” )
@router.get("/me", include_in_schena=Faise)
async def get_user(request: Request, response: Response, token = ""):
user = await get_logged_user(token)
if user:
response. set_cookie(key="access_token”, valuestoken, expires-tinedelta(user[“exp"] - 48 - int(time()}}, httponly-True)
response.status_code = 387
response.headers{"Location™] = “/"
retura True
if "access_token” not in request. cookies.keys():
return RedirectResponse(’/login’)
return await get_logged_user(request.cookies[“access_token”])
@router.get(”/auth_example”)
async def example_auth_required_endpoint(current_user = Oepends(get_logged_user)):
return current_user
Y@rsgeneral .py T
import signal
def timeout(seconds=38, error_message=‘Function call tised out’):
def decorator(func):
def _handle_timeout(signum, frame):
raise TimeoutError(error_message)
def wrapper(*args, **kwargs):
signal.signal(signal.SIGALRM, _handle_timeout)
signal. alarm(seconds)
try:
result = func(*args, **kwargs)
finally:
signal. alarm(@)
return result
return wrapper
return decorator

return wrapper
return decorator
l@e$logging.py
from elasticsearch import Elasticsearch
inport logging
from time import tise
class ElasticsearchHandler (logging Handler):
def init__(self, urls, index, username, password):
super(}._init_()
self.urls = urls
self. index = index
self.usernane = username
self.password = password
self.connection = Elasticsearch(hostseself.urls, http_auth=(self.usernane, self.password), verify certssFalse, ssI_show_warn=False)
def emit(self, record):
try:
msg = self. format(record)
#self. connection. index(index=f" {self index}-{str(datetime.now(pytz-timezone("Asia/Tel_Aviv™)).strftime("2¥-%a-2d"))}', body=msg)
self connection. index(index=self index, body=msg)
except Exception as e:
print(F"Couldn’t Index Log: {e}")
def format(self, record):
return {
‘message’: record.getMessage(),
"level": record.levelnane,
*@timestanp': int(time()),
*autonation_Ad': getattr(record, ‘id’, Wone), I
“name': getattr(record, ‘automation_name’, None),
‘progress’: getattr(record, ‘progress’, None),
‘parameters’: getattr(record, ‘parameters‘, None),
‘state’: getattr(record, ‘state’, None)
}
l@e$task_manager.py
import asyncio, inspect, logging
from fastapi-exceptions import HITPException
from fastapi.responses import RedirectResponse
from fastapi import webSocket
from celery import Celery
from celery.result import AsyncResult
rom functools import wraps
from celery.utils.log import get_task_logger
fron .logging import ElasticsearchMandler
from copy import copy
from celery.schedules import crontab
from typing import Any
from ..src.Archive import ArchiveAlert
neem pra CI ACTTFC Cabral IGIE ELACTTFEEAGRU Tency rclenw Taye THmtr VAEWA TACVE EAATCTDAN CCDIKUG PEICRY TAGYS fnlbceTind Fcecow Tasen rramceTeng RETATIE VACKA AITTTMATTNOT AITTU

ee
from celery.schedules import crontab
from typing import Any
from ..src.Archive import ArchiveAlert
from . config import HURRICANE_AUTH, ELASTICSEARCH_URLS, ELASTICSEARCH INDEX, CELERY_TASKS TOPIC, KAFKA_TASKS_BOOTSTRAP_SERVERS, CELERY TASKS COLLECTION, CELERY_TASKS_CONNECTION_DETATLS, KAFKA_AUTOMATIONS_AUTH,
DOMAIN_FQDN, AUTOMATIONS_ELASTIC_TRACK
class AutomationManager(Celery):
task_registry: dict = {}
async def list_tasks (self):
tasks = copy(self. tasks)
for task_name, task_obj in self.tasks.items():
if “celery.” in task name:
‘tasks. pop(task_nane, None)
return tasks
async def list_autonations(self):
auto = {}
for task_name, task_obj in self.tasks.items():
if “celery.” in task_name:
continue
autoftask_name] = {“description™: f~{self.task_registry[task_name]["description’]}",
“arguments”: {k: str(v) for k, v in self.task_registry[task_nane][“argunents”].items()}}
return auto
async def list_tasks_names(self):
return [task_name for task name in self.tasks.keys() if “celery.” not in task_name]
I
async def get_task(self, task_name):
return self.tasks[task_nane]
async def get_args(self, task_name):
args = self.task_registry[task_name]{“arguments”].itens()
return {k: str(v) for k, v in args}
async def run_task(self, task_name, **kwargs):
await self.check_args(task_name, kwargs)
res = await asyncio.to_thread(self.send_task, task_name, args-[False], kwargs=kwargs)
return await asyncio.to_thread(res-get)
async def schedule task(self, task_name, **kwargs):
await self.check_args(task_nane, kwargs)
return await asyncio.to_thread(self.send_task, task name, args=[False], kwargs=kwargs)
ce reek nptpernt inn nama anchdon wibuamnets

eee oa
from celeepusshadaiesaimpoke.toonhabad(self.send_task, task_nane, args=[False], kwargs-kwargs)
from typing import Any
from ..src.archive import ArchiveAlert
Fronasynondé§ import lHvaRECRHECAETHsuEDASTIOSEAREE,URESDIERASTERHEAREY:TNDEX, CELERY_TASKS_TOPIC, KAFKA_TASKS BOOTSTRAP_SERVERS, CELERY_TASKS COLLECTION, CELERY_TASKS_CONNECTION_DETAILS, KAFKA_AUTOMATIONS_AUTH,
DOMATN_FQDH; tAYEORATRONE tgs TAOL@MACKON_name, kwargs)
guto = await asyncio.to thread(self.send_task, automation_name, args«[dict(archive) if len(dict(archive); != @ and archive else False], kwargsekwargs)
return RedirectResponse(AUTOMATIONS_ELASTIC_TRACK.replace(“<automation_id>”, auto.id))
class AutomationHanager (Celery):
bagkcregisthyckdacgsés€}¥, task_name, args):
# Check if the task exists
asyné fdeSsiistmeashs (de1691f task registry:
‘tasksaéseopy(Betfepaitsy status_code=404, detail-"Task not found”)
fothtabkifiakes tagknebisierself.thekeighems{pe and no garbage args
For afg"coheryaPginatankinapegs.items():
expetackstpop(tasklfameskNong}stry[task_nane][”arguments”].get(arg_name, Exception)
retueh tapksted_type is Exception:
raise HTTPException(status_code=4@0, detail-f"Got unexpected argument {arg_name}")
if expected_type is not None and not isinstance(arg_value, expected_type):
async def listisatunationa(sélf}status_code=400, detail-f"Invelid type for argument {arg_name}"}
auto = {}
for task name, task_obj in self.tasks.items():
async aekflfeelerycR_tastasklfgmesbsocket: WebSocket, task_id):
res = Asgontdnuet(task_id)
«nilautoftaskinane]rei(“desthiptignts fl{se]f.task_registry[task_name]("description’ ]}",
avait asyncio.slesptarguments": {k: str(v) for k, v in self.task_registry[task_nane](“argunents”].items()}}
retuenzauto2bsocket.sena_jso-/{"id". task_id, “state”: res.state, “progress” res.info})
retucr await as."c¢io.to_threadires get,
async def list_tasks_names(self):
2: "petatneptaskznamesfor task,namecindself.tasks.keys() if “celery.” not in task_nane]
rez = eseechesult tesk_id
St aua.n goed: to cheese res reaay I
async def-get-task(selfyvtask:mame)222 "2:.g27
return selfttasks[task.namaj:- -25.2-+-
async-def-get.args(self,stask_name):2122- 9 {72 .dse0 ureieare come @toretac73
-:. =: angs = self.task:registry[task.nane][~argunents”].items()
2. neturn {k-str(v)-foecks win args == 5077
7 te =a : ciple feo Aer pooplite ue ah a Tate LILA elit
async def run_task(self, task_name, **kwargs):- ~ = Poses - e i a
avait sel¥.check_ergs(task_name, kwargs) - ~=
res = await asyncio.to_thread(self.send.task, task_name, args=[False], kwargs-kwargs)
return await asyncio.to_thread(res.get) - -
async def schedule task(self, task_name, **kwargs):
await self.check_args(task name, kwargs)
return await asyncio.to_thread(self.send_task, task name, args-[False], kwargs-kwargs)
banners

ee
task_mansgeornoatatisespnaity. soathedad(Sed€.send task, task name, args-[False], kwargs=kwargs)
task_manager.conf .broker_connection_retry_on_startup = True
task manager-conf-result backend_options = {"database’ : CELERY_TASKS_CONNECTION_DETATLS["database"], ‘taskmeta_collection’: CELERY_TASKS COLLECTION}
taskasynagdefcachedudgodiebackedd, setémgtien(name, archive, **kwargs):
“optamait se]f-check_args(automation_name, kwargs)
dabonsoamast ; aéfnERs, TaSKbreadselfoucnsTtakk[ “datebatkOh_name, args-[dict(archive) if len(dict(archive)} != @ and archive else False], kwargs~kwargs)
} return RediractResponse(AUTOMATIONS ELASTEC_TRACK.replace("<autonation_id>”, auto.id))
t
task_manager. conf. result_backend=CELERY_TASKS_CONNECTION_DETAILS[“string”]
taskanynagdefcohéckeatgs(bedajetask’nabefiarge)e_alerts Smin‘: {"task': ‘autofix_scan_alerts’, “schedule”: crontab(minute='*/5’)}}
# Check if the task exists
if task_nane not in self.task_cegistry:
def automat inal setdTTeExpaption¢stotysicodtaddapadétal]-AisekinotAfiguad?31se) +:
def #eCheakoitfthe)argunents are of the right type and no garbage args
fonsbrganames angkYblud-Invergsaitesiag}:__name__, tags-[func.__module_])
furapspécted_type = self.task_registry[task_name]["arguments”].get(arg_name, Exception)
def dfapnpecteiftyperes, EXCeptigs) :
loggeaisegTTPExteptiga(statdsnend’=400, detail-f"Got unexpected argument {arg_name}”}
iSgexpectetetypéliggaog.Wuke)and not isinstance(arg_value, expected type):
LoggeaiseoMFEBEnception¢status_code=400, detail-f* Invalid type for argunent {arg_name}")
if aot any(isinstance(handler, ElasticsearchHandler) for handler in logger handlers):
async def Livegthackleask(S&ifsimebsockutodWebSOckEESCEBSRCHADELS, ELASTICSEARCH INDEX,
res = AsyncResult(task_id) HURRICANE_AUTH["username”], HURRICANE_AUTH[“password”])
while notoggaitaasynodoctoi thread(ées}ready):
await asyncio,sleep(0.1)
amakterwebSocketssends4sdn(4{Med”: akaSkaidsd"statera-Gescstate] {peageess!2,res.info})
return await asyncio.to_thread(res.get) automation_name’) se_f.1am2,
“progress "OR,
"state STARTED’ ,
async def get_task_status(self, task_id): oeramecers': kuargs”)
res = AsyncResult(task_id)
1 await sasyncio:terthread(reszready):=-"" I
eetura dwaitzasyncioxto;thread(pesiget) r2cs-0-tou"
return alait-asyncio.to.thread({res,info) -<i- rec_2it iv
gov vecicr_aswe ge frame,
cecgrszi = f.nav cucract. flcec tects: steps *10R EF kif Luuncceecaitme cotasteps y favat, int) tase te
task_manager = AutomationManager (‘task manager; =inclades{ "hurticane-home.automations”])
‘task_manager.conf-task-serializer-=.' json’: 20222
task_manager.conf.task_default_queue = CELERY_TASKS_TOPIC
‘task_manager.coné.broker_url.= “confiuentkafka://* + 7;7.join([f"{b. split(':*)[@)}-{DOMAIN_FQON}:{b. split(*:')[1]}" for b in KAFKA_TASKS_BOOTSTRAP_SERVERS.split(”,"}])
task_manager.conf.broker_transport_options = {"kafka_common config":{ ©: 1? =7+
oo “bootstrap. servers’ ::"," join([f"{b-split(‘:'}[8}}.{DOMAIN_FOON}:{b. split(":"}(2]}" for b in KAFKA_TASKS_BOOTSTRAP_SERVERS.split(",")]),
“sasl.mechanisa’; 'SCRAM-SHA-256',
“security.protocol': "SASL_PLAINTEXT",
‘sasl.username': KAFKA_AUTOMATIONS_AUTH[ ‘username’ ],
*sasl.password': KAFKA_AUTOMATIONS_AUTH[ ‘password '],,
“client.id': KAFKA_AUTOMATIONS_AUTH[ ‘username’ ],,
*group.id" : KAFKA_AUTOMATIONS_AUTH[ ‘username’ ]
i
task_manager.conf.task_track_started = True
‘task_manager .conf.broker_connection_retry_on_startup = True
task manager. conf.result_backend_options = {“datebase’: CELERY_TASKS CONNECTION _DETATLS["database"], ‘taskmeta_ collection’: CELERY_TASKS COLLECTION}
ee use og

i aa a
task_manager.conf.task_track_started = True ‘automation_nane’: self.name,
task_manager.conf .broker_connection_retry_on_startup = True ‘progress’: °N/A’,
task_managerconf.result_backend_options = {database": CELERY_TASKS_CONNECTIONSOGTAILS[FAaLEBdse"], ‘taskmeta_collection': CELERY_TASKS_COLLECTION}
task_manager.conf.mongodb_backend_settings = { ‘parameters’: kwargs})
“options” : faise e
“authSource”: CELERY_TASKS_CONNECTZON_DETAILS["database™]
} logger info(#'Task {self.name} has Finished: {str(res)}', extra={"id'; self-request.id,
} *automation_name': self.nane,
‘task_nanager conf .result_backend=CELERY_TASKS_CONNECTION_DETATLS["ptogng34": '100.00%",
task_manager.conf.beat_schedule © {‘autofix_scan_alerts Smin": {"taskte’ !adsv€igsstan alerts", ‘schedule’: crontab(minute-"*/5')}}
“parameters’; kwargs})
try:
def automation(tétakegtép}+1, description="Automation", AutoFix: Any = False):
def decorator(funtget = ArchiveAlert(**args[@])
@task_manageeltesk¢bindépedey naét{fang7 name, tags=[func._module_})
@uraps (func)asyncio. run(alert.send_to_archive())
def arappertsedft iargs,et*kwargs) +
logger iat gétcbadtinloggertiedthdame) {self request.id} :{str(e)}:{args}")
Loggen.setLevel (logging. INFO)
logger.propagate = False
Add the function to the registry
sig &finoheeny¢igiasteacéhahdler, ElasticsearchHandler) for handler in logger.handlers):
task_mandggrhandberesi Bias ffaseanchHand]ér¢ELASTEOSEARGH : URDSpcE LASTZESEARGHAINDEX;f param.annotaticn is rot inspect.Parameter.empty else Nene
HURRTCANBAUTHE Sasérnang” JarHURRECANETAUTH Tpassmecd?}}ion”: description, “autofix”: AutoFix}
task_nandgggeteaddMagdier(1égrhandien}__]["arguments”] .pop("self’, None)
reture arapoer
return doggercinfo(f*Task {self.name} has Started’, extra={"id': self.request.id,
*automation_name": self.name,
‘progress’: "OX",
‘state’: "STARTED',
‘parameters’: kwargs})
def update_progress(current, output=""): I
self. update_state(state="PROGRESS‘, meta-output)
dogger.info(output, extrae{*id’: self.request.id,
‘automation_nane': self.name,
‘progress’: #°{Float(current)/float(total_steps)*1e0: .2f}%" 1 isinstance(type(total_steps), (float, int)) else "2%",
“state‘’: ‘PROGRESS‘})
self.update_progress = update_progress
sig « inspect.signature(func)
defaults = {nane: paran.default for name, param in sig.parameters.items()
if paran.default is not inspect.Paraneter.empty}
for nae, default_value in defaults. items():
Af name not in kwargs:
kwargs[nane] © default_value
try:
res = func(self, **kwargs)
except Exception as e:
logger.error(f‘Task {self.name} has Failed: {str(e)}’, extras{‘1d’: self.request.id,
‘automation nana": self.nane,
"progeess’: f°N/A",
‘state’: ‘FAILED’,
Peneeee ss kianeh

rh = Daa a
‘automation_name’: self.name,
‘progress’: #°N/A‘,
‘state’: "FATLED',
‘parameters’: kwargs})
raise e
Logger -info(f'Task {self.name} has Finished: {str(res)}", extra={"id': self.request.id,
‘automation_name’: self.nane,
“progress': '180.00X",
“state”: ‘SUCCESS’,
‘parameters: kwargs})
try:
if args{e):
alert = Archivealert(**args[@])
alert.description = f*{res}”
asyncio.run(alert.send_to_archive())
except Exception as e!
print(f*Couldn't archive Alert {self.request.1d}:{str(e)}:{args}”)
return res
# Add the function to the registry
sig = inspect.signature(func)
task_nanager.task_registry[func.__name_] = {"arguments”: {name: param.annotation if param.annotation is not inspect.Parameter.enpty else None
for name, param in sig.parameters.items()}, "description": description, “autofix": AutoFix}
task_manager.task_registry[func.__name__J[”arguments”].pop(‘self*, None)
return wrapper
return decorator
I
